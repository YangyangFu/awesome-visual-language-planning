# Visual Language Model in Robotics Control

## 2023
- RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control, [[HomePage]](https://robotics-transformer2.github.io/), [[Paper]](https://robotics-transformer2.github.io/assets/rt2.pdf)
- VoxPoser: composable 3d value maps for robotic manipulation with language models, [[HomePage]](https://voxposer.github.io/), [[Paper]](https://voxposer.github.io/voxposer.pdf).
- PaLM-E: An Embodied Multimodal Language Model, [[HomePage]](https://palm-e.github.io/), [[Paper]](https://palm-e.github.io/assets/palm-e.pdf)
- Code as Policies: Language Model Programs for Embodied Control, [[HomePage]](https://code-as-policies.github.io/)
